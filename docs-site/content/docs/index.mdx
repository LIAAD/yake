# Yet Another Keyword Extractor (YAKE!)

**Unsupervised, corpus-independent keyword extraction from single documents.**

YAKE! (Yet Another Keyword Extractor) is a lightweight, unsupervised automatic keyword extraction system. It uses statistical text features from **single documents** ‚Äî without relying on external corpora, dictionaries, or domain-specific knowledge ‚Äî to extract the most relevant keywords.

YAKE! is designed to be:
- üß† **Unsupervised** ‚Äì no training data required
- üåç **Language & domain independent** ‚Äì works across domains and languages
- üìÑ **Single-document based** ‚Äì no need for a reference corpus
- ‚ö° **Efficient** ‚Äì lightweight and fast

## Why YAKE!?

In an era where data is abundant and multilingual content is common, keyword extraction must be fast, adaptable, and reliable. YAKE! is built to handle:
- Small or large documents
- Texts in various languages
- Environments with limited or no training data

Unlike traditional approaches, YAKE! doesn't depend on NLP pipelines or annotated datasets. It instead uses a combination of text features like word frequency, position, and casing to compute keyword relevance scores.

## Try It Out

- üß™ [Online Demo](http://yake.inesctec.pt)
- üêç [GitHub Repository](https://github.com/LIAAD/yake)

## Install YAKE!

You can use YAKE! via:

### ‚ñ∂Ô∏è Python Package

```bash
pip install git+https://github.com/LIAAD/yake
```

## How It Works

YAKE! assigns relevance scores to keywords based on multiple features:
- Term frequency
- Term position
- Word casing
- Sentence placement
- Contextual diversity

The lower the score, the more relevant the keyword.

## Example (Python)

```python
import yake

text = "Google is acquiring Kaggle, a platform for machine learning competitions..."
kw_extractor = yake.KeywordExtractor()
keywords = kw_extractor.extract_keywords(text)

for kw in keywords:
    print(kw)
```

#### Usage (Command line)

How to use it on your favorite command line

``` bash
Usage: yake [OPTIONS]

Options:
	  -ti, --text_input TEXT          Input text, SURROUNDED by single quotes (')
	  -i, --input_file TEXT           Input file
	  -l, --language TEXT             Language
	  -n, --ngram-size INTEGER        Max size of the ngram.
	  -df, --dedup-func [leve|jaro|seqm] *
									  Deduplication function.
	  -dl, --dedup-lim FLOAT          Deduplication limiar.
	  -ws, --window-size INTEGER      Window size.
	  -t, --top INTEGER               Number of keyphrases to extract
	  -v, --verbose                   Gets detailed information (such as the score)
	  --help                          Show this message and exit.
```

##### Keyword Deduplication Methods in YAKE

In YAKE (Yet Another Keyword Extractor), the methods `levs`, `jaro`, and `seqm` are used to compute **string similarity** during the **keyword deduplication** process ‚Äî that is, removing keywords that are too similar to each other. Here's what distinguishes each of these methods:

###### üî§ 1. `levs` ‚Äî **Levenshtein Similarity**

* **What it is:** Measures the edit distance between two strings ‚Äî i.e., how many operations (insertions, deletions, substitutions) are needed to turn one string into another.
* **How it's used here:** The distance is **normalized** by the length of the longer string, then converted to a **similarity score**.
* **Formula used:**

```python
similarity = 1 - Levenshtein.distance(cand1, cand2) / max(len(cand1), len(cand2))
```

* **Advantages:**
   * Very accurate for small changes (e.g., "house" vs "horse").
   * Considers **character positions**.
* **Disadvantage:**
   * **Slower** than other methods, due to calculating edit operations.

###### 2. `jaro` ‚Äî **Jaro Similarity**

* **What it is:** Measures similarity based on matching characters and their relative positions.
* **Note:** YAKE uses the `jellyfish` library implementation.
* **How it works:** Gives more weight to **nearby matching characters** and penalizes character misalignments.
* **Score:** Ranges from 0.0 (completely different) to 1.0 (identical).
* **Advantages:**
   * More **tolerant of transpositions** (e.g., "maria" vs "maira").
   * Faster than Levenshtein.
* **Disadvantage:**
   * May be less accurate for strings with big length differences.

###### 3. `seqm` ‚Äî **SequenceMatcher Ratio**

* **What it is:** Uses Python's built-in `difflib.SequenceMatcher`, which measures similarity based on **common subsequences**.
* **How it works:** Detects matching blocks and computes a ratio:

```python
ratio = 2 * M / T
```

where `M` is the number of matching characters, and `T` is the total number of characters in both strings.

* **Advantages:**
   * Good for detecting shared blocks in longer strings.
   * Reasonably fast.
* **Disadvantage:**
   * Can be **too sensitive** to small changes in short strings.

######  Which one to use?

| Name | Based on | Best for... | Performance |
|------|----------|-------------|------------|
| `levs` | Edit operations | Typos and small changes | Medium |
| `jaro` | Matching character positions | Names and short strings with swaps | Fast |
| `seqm` | Common subsequences | General phrase similarity | Fast |

######  Practical Example:

| Compared Strings | `levs` | `jaro` | `seqm` |
|------------------|--------|--------|--------|
| "casa" vs "caso" | 0.75 | 0.83 | 0.75 |
| "machine" vs "mecine" | 0.71 | 0.88 | 0.82 |
| "apple" vs "a pple" | 0.8 | 0.93 | 0.9 |

**Recommendation:** For general use with a good balance of speed and accuracy, `seqm` is a solid default (and it is YAKE's default). For stricter lexical similarity, choose `levs`. For names or when letter swaps are common, go with `jaro`.
###### Highlighting Keywords

```python
from yake.highlight import TextHighlighter

th = TextHighlighter(max_ngram_size=3)
highlighted = th.highlight(text, keywords)
```

## Benchmarks

YAKE! has been evaluated against 10+ state-of-the-art methods across 20+ datasets. See our paper in Information Sciences Journal for details.

## References
Please best cite suited work when using YAKE

<b>In-depth journal paper at Information Sciences Journal</b>

Campos, R., Mangaravite, V., Pasquali, A., Jatowt, A., Jorge, A., Nunes, C. and Jatowt, A. (2020). YAKE! Keyword Extraction from Single Documents using Multiple Local Features. In Information Sciences Journal. Elsevier, Vol 509, pp 257-289. [pdf](https://doi.org/10.1016/j.ins.2019.09.013)

<b>ECIR'18 Best Short Paper</b>

Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2018). A Text Feature Based Automatic Keyword Extraction Method for Single Documents. In: Pasi G., Piwowarski B., Azzopardi L., Hanbury A. (eds). Advances in Information Retrieval. ECIR 2018 (Grenoble, France. March 26 ‚Äì 29). Lecture Notes in Computer Science, vol 10772, pp. 684 - 691. [pdf](https://link.springer.com/chapter/10.1007/978-3-319-76941-7_63)

Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2018). YAKE! Collection-independent Automatic Keyword Extractor. In: Pasi G., Piwowarski B., Azzopardi L., Hanbury A. (eds). Advances in Information Retrieval. ECIR 2018 (Grenoble, France. March 26 ‚Äì 29). Lecture Notes in Computer Science, vol 10772, pp. 806 - 810. [pdf](https://link.springer.com/chapter/10.1007/978-3-319-76941-7_80)
